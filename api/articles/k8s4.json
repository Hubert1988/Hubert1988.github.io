{"title":"K8s-集群监控","uid":"436f5c4cd9584648ea4f3adf32eabb95","slug":"k8s4","date":"2022-06-29T10:49:36.000Z","updated":"2022-07-17T15:25:16.217Z","comments":true,"path":"api/articles/k8s4.json","keywords":null,"cover":"https://pic4.zhimg.com/v2-562267b2cf39fded4c66640ac37ee818_1440w.jpg?source=172ae18b","content":"<ul>\n<li><ul>\n<li><h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>随着k8s的崛起，我们迎来了PASS层的落地，服务的部署愈发方便，但为服务提供支持的架构却愈发具有挑战性，在k8s中，多个服务和命名空间可以跨基础设施分布，每个服务都是由 pods 组成，而 pod 可以包含一个或多个容器。从底层服务的架构来说是变得复杂，所以为了更好的掌握集群的状态，发生故障时，能够及时的预警，及时止损和增加稳定性，对集群的监控是必不可少的。</p>\n<p>关于监控系统的基础大家可以参考<a href=\"https://bytedance.feishu.cn/docx/doxcnygruXM8Humu43PDnFbY7Vg\">监控系统</a> ，对监控系统有个基础的了解。</p>\n<h1 id=\"K8S内部监控工具\"><a href=\"#K8S内部监控工具\" class=\"headerlink\" title=\"K8S内部监控工具\"></a>K8S内部监控工具</h1><ul>\n<li><p>在K8S内部，我们最熟悉的监控组件就是探针（Probes），K8S会利用探针对容器进行探测，如果 Probe 检测到容器不健康，那么它就会重启容器。基于探针技术，K8S可以自己及时发现故障并且自愈。而探针也分为下面几类：</p>\n</li>\n<li><ul>\n<li>livenessProbe</li>\n<li>readinessProbe</li>\n<li>startupProbe</li>\n</ul>\n</li>\n</ul>\n<p>Kubernetes 有从故障中自动恢复的强大能力。如果进程发生崩溃，它可以重新启动 pods，如果节点出现错误，它能重新分配 pods。但是在生产环境中，K8S并不是万能的，总会出现K8S自己不能解决的问题，所以我们为了保证集群的健康状态，用专业的工具对K8S集群进行监控就尤为重要。</p>\n<h1 id=\"黑-x2F-白盒监控\"><a href=\"#黑-x2F-白盒监控\" class=\"headerlink\" title=\"黑&#x2F;白盒监控\"></a>黑&#x2F;白盒监控</h1><ul>\n<li><p>概述</p>\n<ul>\n<li><p>k8s的指标监控我们可以大致分为黑盒监控与白盒监控，我们可以利用因果来理解他们，白盒监控是因，黑盒监控是果，白盒探测关注的组件的内部状态，即探究的因，而黑盒监控探测关注的是组件的结果状态。白盒监控主要关注的是原因，也就是系统内部暴露的一些指标，例如 redis 的 info 中显示 redis slave down，这个就是 redis info 显示的一个内部的指标，重点在于原因黑盒监控主要关注的现象，一般都是正在发生的东西，例如出现一个告警，业务接口不正常，那么这种监控就是站在用户的角度能看到的监控，重点在于能对正在发生的故障进行告警。举例来说，我们可以利用白盒监控集群的IO，响应的延时，黑盒监控集群不同组件此刻状态的好坏。</p>\n</li>\n<li><p><img src=\"https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=ZTY5NjFjMTllMjY5YzRlYzk3NzgyMjczZDliZjZmNTBfSU9OckJDa2xwMXhNOFc0QlB5SUJLV0xKSjFVY2N1QTdfVG9rZW46Ym94Y251c2g2R2dZSWZ2UGM0dVpEdWRCUXBlXzE2NTgwNzEwNjA6MTY1ODA3NDY2MF9WNA\" alt=\"img\"></p>\n</li>\n</ul>\n</li>\n<li><p>黑盒监控：</p>\n<ul>\n<li>对于k8s集群的黑盒监控，我们可以通过HTTP，TCP，ICMP一些基础的网络协议对k8s相关组件暴露的端口呀进行探测，比如用HTTP协议向Master节点的apiserver发起http请求，如果返回的状态码正常，说明该组件工作正常，在这个时间点，是属于健康状态。然后对探测的结果进行上报。而我们通过黑盒监控一些比如 apiserver，etcd，scheduler，contraller，kubelet等一些集群重要组件的存活响应状态。</li>\n</ul>\n</li>\n<li><p>白盒监控</p>\n<ul>\n<li><p>我们从白盒监控的核心理念出发，来检测k8s集群的“因”，对此，谷歌对于这些指标阐述了一个方法论，即四个黄金指标</p>\n<ul>\n<li>错误：错误是指当前系统发生的错误请求和错误率</li>\n<li>延迟：服务请求所需时间</li>\n<li>流量：当前系统的流量<ul>\n<li>流量指标可以指系统层面的网络和磁盘IO，服务层面的QpS、PV和UV等数据。流量和突增或突减都可能预示着系统可能出现问题（攻击事件、系统故障…）</li>\n</ul>\n</li>\n<li>饱和度：用于衡量当前服务的利用率<ul>\n<li>更为通俗的讲，饱和度可以理解为服务的利用率，可以代表系统承受的压力。所以饱和度与流量息息相关，流量的上升一般也会导致饱和度的上升。通常情况下，每种业务系统都应该有各自的饱和度指标。在很多业务系统中，消息队列长度是一个比较重要的饱和度指标，除此之外CPU、内存、磁盘、网络等系统资源利用率也可以作为饱和度的一种体现方式。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>基于这四个指标我们可以由“因”对k8s集群状态进行监控和分析，但是这并不绝对，针对于不同的具体业务，指标应该具体分析，有时甚至需要埋点，侵入式的进行监控数据采集。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"主流监控方案\"><a href=\"#主流监控方案\" class=\"headerlink\" title=\"主流监控方案\"></a>主流监控方案</h1><h2 id=\"Promethus\"><a href=\"#Promethus\" class=\"headerlink\" title=\"Promethus\"></a>Promethus</h2><ul>\n<li><p>是什么？</p>\n<p>Prometheus 是一款基于时序数据库的开源监控告警系统。</p>\n</li>\n<li><p>原理：</p>\n<ul>\n<li>​     Prometheus的基本原理是通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控。</li>\n</ul>\n</li>\n<li><p>特点：</p>\n<ul>\n<li>支持多维数据模型：由度量名和键值对组成的时间序列数据</li>\n<li>内置时间序列数据库TSDB</li>\n<li>支持PromQL查询语言，可以完成非常复杂的查询和分析，对图表展示和告警非常有意义</li>\n<li>支持HTTP的Pull方式采集时间序列数据</li>\n<li>支持PushGateway采集瞬时任务的数据</li>\n<li>支持服务发现和静态配置两种方式发现目标</li>\n<li>支持接入Grafana</li>\n</ul>\n</li>\n<li><p>架构：</p>\n<ul>\n<li><p><img src=\"https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=NGNkYWFkOTE5YjM2NTMxM2M2YmViODUzMzk5NjJlMmNfUGVsenhMb1R3Y3Z0bEdSdzNaSFFmVGFtYVlQTllOaFhfVG9rZW46Ym94Y25WeUZvb0gySTJ4NUtxdUt3OFVHUGhiXzE2NTgwNzEwNjA6MTY1ODA3NDY2MF9WNA\" alt=\"img\"></p>\n</li>\n<li><p>总体来说，Promethus的架构可以分为三个部分，分别为数据的采集，存储和消费。而实现其中核心的是Promethus Server这个组件</p>\n</li>\n<li><p>核心（Prometheus Server）</p>\n<ul>\n<li>Retrieval: 获取监控数据</li>\n<li>TSDB: 时间序列数据库(Time Series Database)，我们可以简单的理解为一个优化后用来处理时间序列数据的软件，并且数据中的数组是由时间进行索引的。具备以下特点：<ul>\n<li>大部分时间都是顺序写入操作，很少涉及修改数据</li>\n<li>删除操作都是删除一段时间的数据，而不涉及到删除无规律数据</li>\n<li>读操作一般都是升序或者降序</li>\n</ul>\n</li>\n<li>HTTP Server: 为告警和出图提供查询接口</li>\n</ul>\n</li>\n<li><p>数据采集</p>\n<ul>\n<li>Exporters: Prometheus的一类数据采集组件的总称。它负责从目标处搜集数据，并将其转化为Prometheus支持的格式。与传统的数据采集组件不同的是，它并不向中央服务器发送数据，而是等待中央服务器主动前来抓取</li>\n<li>Pushgateway: 支持临时性Job主动推送指标的中间网关</li>\n</ul>\n</li>\n<li><p>服务发现（Service Discovery）</p>\n<ul>\n<li>Kubernetes_sd: 支持从Kubernetes中自动发现服务和采集信息。而Zabbix监控项原型就不适合Kubernets，因为随着Pod的重启或者升级，Pod的名称是会随机变化的。</li>\n<li>file_sd: 通过配置文件来实现服务的自动发现</li>\n</ul>\n</li>\n<li><p>告警管理（Altertmanager）</p>\n<ul>\n<li>通过相关的告警配置，对触发阈值的告警通过页面展示、短信和邮件通知的方式告知运维人员。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Thanos\"><a href=\"#Thanos\" class=\"headerlink\" title=\"Thanos\"></a>Thanos</h2><ul>\n<li>是什么<ul>\n<li>Thanos 是一个基于 Prometheus 实现的监控方案，其主要设计目的是解决原生 Prometheus 上的痛点，并且做进一步的提升，主要的特性有：<strong>全局查询，高可用，动态拓展，长期存储</strong>。下图是 Thanos 官方的架构图：</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=MmQ0NWI4NDljYWZmNTkzYjg1NDI1NTEyMDNmOGFmZTVfV2NmSm9jRW5KTVdPUFZhN3hzRDFVT1M2VUFiRkdpeTJfVG9rZW46Ym94Y25EUHROU0k4cmRzeGVvU0V4MG1ZRDRmXzE2NTgwNzEwNjA6MTY1ODA3NDY2MF9WNA\" alt=\"img\"></p>\n<ul>\n<li><p>构成</p>\n<ul>\n<li><p>Thanos 主要由如下几个特定功能的组件组成：</p>\n</li>\n<li><p>边车组件（Sidecar）：连接 Prometheus，并把 Prometheus 暴露给查询网关（Querier&#x2F;Query），以供实时查询，并且可以上传 Prometheus 数据给对象存储例如s3，以供长期保存</p>\n</li>\n<li><p>查询网关（Querier&#x2F;Query）：实现了 Prometheus API，与汇集底层组件（如边车组件 Sidecar，或是存储网关 Store Gateway）的数据</p>\n</li>\n<li><p>存储网关（Store Gateway）：将云存储中的数据内容暴露出来</p>\n</li>\n<li><p>压缩器（Compactor）：将云存储中的数据进行压缩和下采样</p>\n</li>\n<li><p>接收器（Receiver）：从 Prometheus 的 remote-write WAL（Prometheus 远程预写式日志）获取数据，暴露出去或者上传到云存储</p>\n</li>\n<li><p>规则组件（Ruler）：针对监控数据进行评估和报警</p>\n</li>\n<li><p>Bucket：主要用于展示对象存储中历史数据的存储情况，查看每个指标源中数据块的压缩级别，解析度，存储时段和时间长度等信息。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><ul>\n<li>当我们了解监控系统后，会发现promthus是仿佛就是完美的监控系统实现，这也是为什么promthus是k8s的监控系统标准，promthus确实好，但是事物都有两面性，尽管promthus接入k8s简单，单机性能强悍，还开源，但是到了大规模的场景，却显得力不从心，尽管有了联邦，但是效果甚微，以至于后来出现了Thnaos的大型分布式的监控解决方案，可以很好的适配promthus，但是却并没有全面的落地。而目前可能对于大规模的集群监控方案还是得从监控系统出发，有能力的公司可以充分的根据自己的业务进行适配，搭建监控系统。但是技术还在不断的迭代更新，就好比尽管k8s推动了pass的落地，但谁也不确定未来的结果是怎样，正如下面这句话所说的<ul>\n<li><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>  每个技术都有自己的生命周期，越底层的技术生命周期会越长，而越上层的技术生命周期也就越短，虽然 Kubernetes 是当今容器界的扛把子，但是未来的事情没有人可以说的准。我们要时刻清楚手中工具的优点和缺点，花一些时间学习 Kubernetes 中设计的精髓，不过如果在未来的某一天 Kubernetes 也成为了过去，我们也应该感到喜悦，因为会有更好的工具取代它。</p></blockquote>\n</li>\n</ul>\n</li>\n</ul>\n<p>也许目前集群监控方案没有最好的，没有最优解，可能对于当下，最合适的就是最好的吧。</p>\n<p>参考文档：<a href=\"https://juejin.cn/post/6971345895971373092\">主流K8S集群监控方案 - 掘金</a></p>\n</li>\n</ul>\n</li>\n</ul>\n","feature":false,"text":" 背景随着k8s的崛起，我们迎来了PASS层的落地，服务的部署愈发方便，但为服务提供支持的架构却愈发具有挑战性，在k8s中，多个服务和命名空间可以跨基础设施分布，每个服务都是由 pods 组成，而 pod 可以包含一个或多个容器。从底层服务的架构来说是变得复杂，所以为了更好的掌握...","link":"","photos":[],"count_time":{"symbolsCount":"3.7k","symbolsTime":"3 mins."},"categories":[{"name":"K8s","slug":"K8s","count":4,"path":"api/categories/K8s.json"}],"tags":[],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E8%83%8C%E6%99%AF\"><span class=\"toc-text\">背景</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#K8S%E5%86%85%E9%83%A8%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7\"><span class=\"toc-text\">K8S内部监控工具</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E9%BB%91-x2F-%E7%99%BD%E7%9B%92%E7%9B%91%E6%8E%A7\"><span class=\"toc-text\">黑&#x2F;白盒监控</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%BB%E6%B5%81%E7%9B%91%E6%8E%A7%E6%96%B9%E6%A1%88\"><span class=\"toc-text\">主流监控方案</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Promethus\"><span class=\"toc-text\">Promethus</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Thanos\"><span class=\"toc-text\">Thanos</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%80%BB%E7%BB%93\"><span class=\"toc-text\">总结</span></a></li></ol>","author":{"name":"Hubert","slug":"blog-author","avatar":"https://tse2-mm.cn.bing.net/th/id/OIP-C.HOHe3l1T_0UEexBraXs53wAAAA?w=169&h=176&c=7&r=0&o=5&dpr=1.38&pid=1.7","link":"/","description":"<h5>This is my own blog to     share my knowledge</h5>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"监控系统","uid":"d92ff721ecc7f2b8c5a903b25ff0b67c","slug":"k8s3","date":"2022-07-17T15:22:34.206Z","updated":"2022-07-17T15:24:53.456Z","comments":true,"path":"api/articles/k8s3.json","keywords":null,"cover":"https://pic4.zhimg.com/v2-562267b2cf39fded4c66640ac37ee818_1440w.jpg?source=172ae18b","text":"前言监控是整个运维乃至整个产品生命周期中最重要的一环，事前及时预警发现故障，事后提供详细的数据用于追查定位问题都依赖于监控，随着PASS层的落地，微服务架构的兴起，监控更是不可缺少的一环，而监控不仅仅是一个组件，而是一个体系，系统，需要有一个完善的生态系统来支撑。通过本文，我们能...","link":"","photos":[],"count_time":{"symbolsCount":"1.9k","symbolsTime":"2 mins."},"categories":[{"name":"K8s","slug":"K8s","count":4,"path":"api/categories/K8s.json"}],"tags":[],"author":{"name":"Hubert","slug":"blog-author","avatar":"https://tse2-mm.cn.bing.net/th/id/OIP-C.HOHe3l1T_0UEexBraXs53wAAAA?w=169&h=176&c=7&r=0&o=5&dpr=1.38&pid=1.7","link":"/","description":"<h5>This is my own blog to     share my knowledge</h5>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":false},"next_post":{"title":"浅析RPC框架","uid":"6baa7e0b0cfe666ab7d296eb78705886","slug":"rpc","date":"2022-05-12T05:48:25.000Z","updated":"2022-05-12T08:34:01.600Z","comments":true,"path":"api/articles/rpc.json","keywords":null,"cover":"https://pic4.zhimg.com/v2-45d69c22c7149dcf15fc4f6320d400f3_r.jpg","text":"RPC框架基础概念 背景 IPC（进程间的通信）可以有多种方式，比如本地调用，或者通过网络实现远程调用，而rpc就是在微服务的背景下实现的一种通过网络远程服务调用的一种协议。 概念 RPC（远程过程调用，简单的理解是一个节点请求另一个节点提供的服务 ） 本地过程调用和远程调用 本...","link":"","photos":[],"count_time":{"symbolsCount":"2.3k","symbolsTime":"2 mins."},"categories":[{"name":"Frame","slug":"Frame","count":1,"path":"api/categories/Frame.json"}],"tags":[],"author":{"name":"Hubert","slug":"blog-author","avatar":"https://tse2-mm.cn.bing.net/th/id/OIP-C.HOHe3l1T_0UEexBraXs53wAAAA?w=169&h=176&c=7&r=0&o=5&dpr=1.38&pid=1.7","link":"/","description":"<h5>This is my own blog to     share my knowledge</h5>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}